{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "import os\n",
    "import json\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import cv2\n",
    "import nltk\n",
    "import torch\n",
    "import torch.utils.data as tud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = r'/home/anna/pycharm_proj/image_caption/Flickr8k/'\n",
    "input_files_folder = '/home/anna/pycharm_proj/image_caption/input_files/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 获取全部数据集的图像路径与描述"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_folder, 'Flickr8k_text/Flickr8k.lemma.token.txt'), 'r', encoding='utf-8') as fp:\n",
    "    lines = fp.read().split('\\n')\n",
    "image_paths = [line.split('\\t')[0].split('#')[0] for line in lines]\n",
    "image_captions = [nltk.word_tokenize(line.split('\\t')[-1]) for line in lines]\n",
    "# image_paths.remove('')\n",
    "# image_captions.remove('')\n",
    "# del image_captions[-1]\n",
    "# assert len(image_captions) == len(set(image_paths)) * 5 # 5 captions per image\n",
    "image_path2caption = {image_paths[5*i]:image_captions[5*i:5*i+5] for i in range(int(len(image_paths)/5))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 分别将训练集，验证集，测试集读入内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainImages_paths = []\n",
    "trainImages_captions = []\n",
    "devImages_paths = []\n",
    "devImages_captions = []\n",
    "testImages_paths = []\n",
    "testImages_captions = []\n",
    "for split in ['trainImages', 'devImages', 'testImages']:\n",
    "    with open(os.path.join(data_folder, 'Flickr8k_text/Flickr_8k.' + split + '.txt'), 'r', encoding='utf-8') as fp:\n",
    "        path = fp.read().split('\\n')\n",
    "        path.remove('')\n",
    "    caption = [image_path2caption[p] for p in path]\n",
    "    assert len(caption) == len(path)\n",
    "    locals()[split+'_paths'] = path \n",
    "    locals()[split+'_captions'] = caption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 生成word_map并写入 .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 100\n",
    "freq = Counter()\n",
    "for caps in [trainImages_captions, devImages_captions, testImages_captions]:\n",
    "    for cap in caps:\n",
    "        for sentence in cap:\n",
    "            if len(sentence) >= max_len:\n",
    "                print(\"警告！caption的长度大于100 ！\")\n",
    "            freq.update(sentence)\n",
    "\n",
    "min_word_freq = 5\n",
    "words = [w for w in freq.keys() if freq[w] > min_word_freq]\n",
    "word_map = {w: n + 1 for n, w in enumerate(words)}\n",
    "word_map['<unk>'] = len(word_map) + 1\n",
    "word_map['<start>'] = len(word_map) + 1\n",
    "word_map['<end>'] = len(word_map) + 1\n",
    "word_map['<pad>'] = 0\n",
    "\n",
    "input_files_folder = '/home/anna/pycharm_proj/image_caption/input_files/'\n",
    "with open(os.path.join(input_files_folder, 'WORDMAP.json'), 'w') as j:\n",
    "    json.dump(word_map, j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 生成输入数据文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 26/6000 [00:00<00:23, 257.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading TRAIN images and captions, storing to file...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6000/6000 [00:19<00:00, 308.94it/s]\n",
      "  3%|▎         | 29/1000 [00:00<00:03, 285.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading VAL images and captions, storing to file...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 298.30it/s]\n",
      "  3%|▎         | 32/1000 [00:00<00:03, 314.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading TEST images and captions, storing to file...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 314.90it/s]\n"
     ]
    }
   ],
   "source": [
    "for impaths, imcaps, split in [(trainImages_paths, trainImages_captions, 'TRAIN'),\n",
    "                               (devImages_paths, devImages_captions, 'VAL'),\n",
    "                               (testImages_paths, testImages_captions, 'TEST')]:\n",
    "\n",
    "    with h5py.File(os.path.join(input_files_folder, split + '_IMAGES' + '.hdf5'), 'a') as h:\n",
    "        h.attrs['captions_per_image'] = 5\n",
    "\n",
    "        # 创建一个HDF5的dataset来存储images\n",
    "        images = h.create_dataset('images', (len(impaths), 3, 256, 256), dtype='uint8')\n",
    "\n",
    "        print(\"\\nReading %s images and captions, storing to file...\\n\" % split)\n",
    "\n",
    "        enc_captions = []\n",
    "        caplens = []\n",
    "\n",
    "        for i, path in enumerate(tqdm(impaths)):\n",
    "\n",
    "            # Read images\n",
    "            img = cv2.imread(data_folder + 'Flickr8k_Dataset/Flicker8k_Dataset/' + impaths[i])\n",
    "            img = cv2.resize(img, (256, 256))\n",
    "            img = img.transpose(2, 0, 1) # 通道变换为NCHW\n",
    "            assert img.shape == (3, 256, 256)\n",
    "            assert np.max(img) <= 255\n",
    "\n",
    "            # Save image to HDF5 file\n",
    "            images[i] = img\n",
    "\n",
    "            for j, c in enumerate(imcaps[i]):\n",
    "                # Encode captions\n",
    "                enc_c = [word_map['<start>']] + [word_map.get(word, word_map['<unk>']) for word in c] + [word_map['<end>']] + [word_map['<pad>']] * (max_len - len(c))\n",
    "\n",
    "                # Find caption lengths\n",
    "                c_len = len(c) + 2\n",
    "\n",
    "                enc_captions.append(enc_c)\n",
    "                caplens.append(c_len)\n",
    "\n",
    "        # Sanity check\n",
    "        assert images.shape[0] * 5 == len(enc_captions) == len(caplens)\n",
    "\n",
    "        # Save encoded captions and their lengths to JSON files\n",
    "        with open(os.path.join(input_files_folder, split + '_CAPTIONS' + '.json'), 'w') as j:\n",
    "            json.dump(enc_captions, j)\n",
    "\n",
    "        with open(os.path.join(input_files_folder, split + '_CAPLENS' + '.json'), 'w') as j:\n",
    "            json.dump(caplens, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
